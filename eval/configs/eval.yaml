# SearchIt Evaluation Configuration

# Dataset paths
queries_path: "eval/datasets/toy_queries.tsv"
qrels_path: "eval/datasets/toy_qrels.tsv"

# Search configurations to evaluate
search_configs:
  - name: "BM25_Only"
    description: "BM25 search only"
    # Note: This would require gateway modification to support BM25-only mode

  - name: "Dense_Only"
    description: "Vector search only"
    # Note: This would require gateway modification to support dense-only mode

  - name: "Hybrid_RRF"
    description: "Hybrid search with RRF fusion (default)"
    # This is the current default configuration

  - name: "Hybrid_RRF_Reranked"
    description: "Hybrid search with RRF fusion + reranking"
    # This is the current default with reranking enabled

# Ask configurations to evaluate
ask_configs:
  - name: "Default"
    description: "Default ask configuration with grounding"

  - name: "High_Threshold"
    description: "Ask with higher coverage threshold"
    # Note: This would require gateway modification

# Evaluation parameters
evaluation:
  max_queries: 20 # Limit for demo
  timeout_seconds: 30
  retry_attempts: 3

# Metrics to compute
metrics:
  search:
    - recall_at_5
    - recall_at_10
    - recall_at_20
    - mrr
    - ndcg_at_10

  ask:
    - abstain_rate
    - coverage_score
    - response_time

# Baseline comparison
baseline:
  enabled: true
  file: "eval/baselines/baseline_metrics.json"
  thresholds:
    recall_at_10:
      regression_threshold: 0.05 # 5% regression threshold
      improvement_threshold: 0.02 # 2% improvement threshold
    mrr:
      regression_threshold: 0.03
      improvement_threshold: 0.01
    ndcg_at_10:
      regression_threshold: 0.03
      improvement_threshold: 0.01
    abstain_rate:
      regression_threshold: 0.1 # 10% increase in abstain rate
      improvement_threshold: 0.05 # 5% decrease in abstain rate

# Output configuration
output:
  save_detailed_results: true
  generate_plots: true
  include_per_query_metrics: false
